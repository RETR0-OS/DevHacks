100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:27<00:00,  1.01s/it][34m[1mwandb[0m: Adding directory to artifact (.\cache\EleutherAI-gpt-neo-1.3B\checkpoint-25)... Done. 0.2s
{'loss': 2.3896, 'grad_norm': 0.12845298647880554, 'learning_rate': 0.00019914448613738106, 'num_tokens': 656.0, 'mean_token_accuracy': 0.4483004920184612, 'epoch': 0.08}
{'loss': 2.5005, 'grad_norm': 0.16993343830108643, 'learning_rate': 0.0001923879532511287, 'num_tokens': 1235.0, 'mean_token_accuracy': 0.4439128302037716, 'epoch': 0.16}
{'loss': 2.6245, 'grad_norm': 0.2919146716594696, 'learning_rate': 0.00017933533402912354, 'num_tokens': 1707.0, 'mean_token_accuracy': 0.4275914914906025, 'epoch': 0.24}
{'loss': 2.1909, 'grad_norm': 0.2934754490852356, 'learning_rate': 0.00016087614290087208, 'num_tokens': 2332.0, 'mean_token_accuracy': 0.4915211498737335, 'epoch': 0.32}
{'loss': 2.4487, 'grad_norm': 0.39237362146377563, 'learning_rate': 0.000138268343236509, 'num_tokens': 2870.0, 'mean_token_accuracy': 0.44727563858032227, 'epoch': 0.4}
{'loss': 2.6931, 'grad_norm': 0.5126122832298279, 'learning_rate': 0.00011305261922200519, 'num_tokens': 3261.0, 'mean_token_accuracy': 0.40989910066127777, 'epoch': 0.48}
{'loss': 1.9418, 'grad_norm': 0.4212765395641327, 'learning_rate': 8.694738077799488e-05, 'num_tokens': 3905.0, 'mean_token_accuracy': 0.5292730927467346, 'epoch': 0.56}
{'loss': 2.0892, 'grad_norm': 0.46442973613739014, 'learning_rate': 6.173165676349103e-05, 'num_tokens': 4472.0, 'mean_token_accuracy': 0.5068416334688663, 'epoch': 0.64}
{'loss': 2.2942, 'grad_norm': 0.5801839232444763, 'learning_rate': 3.9123857099127936e-05, 'num_tokens': 4932.0, 'mean_token_accuracy': 0.4846017025411129, 'epoch': 0.72}
{'loss': 2.0808, 'grad_norm': 0.40554723143577576, 'learning_rate': 2.0664665970876496e-05, 'num_tokens': 5549.0, 'mean_token_accuracy': 0.5142766460776329, 'epoch': 0.8}
{'loss': 2.2798, 'grad_norm': 0.48495474457740784, 'learning_rate': 7.612046748871327e-06, 'num_tokens': 6095.0, 'mean_token_accuracy': 0.4640848971903324, 'epoch': 0.88}
{'loss': 2.3035, 'grad_norm': 0.6519718170166016, 'learning_rate': 8.555138626189618e-07, 'num_tokens': 6530.0, 'mean_token_accuracy': 0.475268866866827, 'epoch': 0.96}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:27<00:00,  1.01s/it]No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
{'train_runtime': 29.6522, 'train_samples_per_second': 3.372, 'train_steps_per_second': 0.843, 'train_loss': 2.309443359375, 'num_tokens': 6805.0, 'mean_token_accuracy': 0.5144789218902588, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:28<00:00,  1.16s/it]
****************************************************************************************************
Model fine-tuned successfully!
Model save to ./finetuned_models/EleutherAI-gpt-neo-1.3B_TaskType.SEQ_2_SEQ_LM_low_end_finetuned
Try out your new model in our chat playground!
****************************************************************************************************
